{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11465406,"sourceType":"datasetVersion","datasetId":7184789}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport pandas as pd\nimport numpy as np\nimport wandb\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:28:51.496617Z","iopub.execute_input":"2025-04-19T03:28:51.497404Z","iopub.status.idle":"2025-04-19T03:29:03.640535Z","shell.execute_reply.started":"2025-04-19T03:28:51.497380Z","shell.execute_reply":"2025-04-19T03:29:03.639723Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import gc\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nimport matplotlib.pyplot as plt\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:30:26.100605Z","iopub.execute_input":"2025-04-19T03:30:26.100876Z","iopub.status.idle":"2025-04-19T03:30:26.106595Z","shell.execute_reply.started":"2025-04-19T03:30:26.100857Z","shell.execute_reply":"2025-04-19T03:30:26.106042Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:30:29.852678Z","iopub.execute_input":"2025-04-19T03:30:29.853194Z","iopub.status.idle":"2025-04-19T03:30:29.858160Z","shell.execute_reply.started":"2025-04-19T03:30:29.853173Z","shell.execute_reply":"2025-04-19T03:30:29.857436Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(\n        self,\n        input_dimension: tuple,\n        number_of_filters: int,\n        filter_size: tuple,\n        stride: int,\n        padding: int,\n        max_pooling_size: tuple,\n        n_neurons: int,\n        n_classes: int,\n        conv_activation: nn.Module,\n        dense_activation: nn.Module,\n        dropout_rate: float,\n        use_batchnorm: bool,\n        factor: float,\n        dropout_organisation: int,\n    ):\n        super(CNN, self).__init__()\n\n        self.conv_blocks = nn.ModuleList()\n        in_channels = input_dimension[0]\n\n        for i in range(5):\n            out_channels = int((factor ** i) * number_of_filters)\n            out_channels = max(out_channels, 3)\n\n            add_dropout = (i % dropout_organisation) > 0\n\n            conv_block = self.create_conv_block(\n                in_channels,\n                out_channels,\n                filter_size,\n                max_pooling_size,\n                stride,\n                padding,\n                conv_activation,\n                dropout_rate,\n                use_batchnorm,\n                add_dropout,\n            )\n            self.conv_blocks.append(conv_block)\n            in_channels = out_channels\n\n        self.flatten = nn.Flatten()\n\n        # Compute the size after conv layers\n        dummy_input = torch.ones(1, *input_dimension)\n        with torch.no_grad():\n            x = dummy_input\n            for block in self.conv_blocks:\n                x = block(x)\n        in_features = x.view(1, -1).shape[1]\n\n        # Define dense layers\n        self.dense_block1 = nn.Sequential(\n            nn.Linear(in_features=in_features, out_features=n_neurons),\n            dense_activation,\n            nn.Linear(n_neurons, n_classes),\n            nn.LogSoftmax(dim=1),\n        )\n\n    def create_conv_block(\n        self,\n        in_c,\n        out_c,\n        kernel_size,\n        max_pooling_size,\n        stride,\n        padding,\n        conv_activation,\n        dropout_rate,\n        use_batchnorm,\n        add_dropout,\n    ):\n        layers = [\n            nn.Conv2d(in_c, out_c, kernel_size=kernel_size, stride=stride, padding=padding),\n            conv_activation\n        ]\n        if use_batchnorm:\n            layers.append(nn.BatchNorm2d(out_c))\n        layers.append(nn.MaxPool2d(kernel_size=max_pooling_size))\n        if add_dropout:\n            layers.append(nn.Dropout(p=dropout_rate))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        for block in self.conv_blocks:\n            x = block(x)\n        x = self.flatten(x)\n        return self.dense_block1(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:30:30.675185Z","iopub.execute_input":"2025-04-19T03:30:30.675804Z","iopub.status.idle":"2025-04-19T03:30:30.687213Z","shell.execute_reply.started":"2025-04-19T03:30:30.675782Z","shell.execute_reply":"2025-04-19T03:30:30.686346Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Test data path\ntraining_data_path = \"/kaggle/input/nature-12k/inaturalist_12K/train\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:30:31.446108Z","iopub.execute_input":"2025-04-19T03:30:31.446359Z","iopub.status.idle":"2025-04-19T03:30:31.451197Z","shell.execute_reply.started":"2025-04-19T03:30:31.446341Z","shell.execute_reply":"2025-04-19T03:30:31.450440Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:30:31.657452Z","iopub.execute_input":"2025-04-19T03:30:31.658169Z","iopub.status.idle":"2025-04-19T03:30:31.662291Z","shell.execute_reply.started":"2025-04-19T03:30:31.658142Z","shell.execute_reply":"2025-04-19T03:30:31.661688Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Fixed configurations\nconfig = {\n    'number_of_filters': 64,\n    'filter_size': 3,\n    'stride': 1,\n    'padding': 1,\n    'max_pooling_size': 2,\n    'n_neurons': 64,\n    'n_classes': 10,\n    'conv_activation': 'silu',\n    'dense_activation': 'sigmoid',\n    'dropout_rate': 0.2,\n    'use_batchnorm': True,\n    'factor': 3,\n    'learning_rate': 1e-4,\n    'batch_size': 16,\n    'epochs': 15,\n    'use_augmentation': False,\n    'dropout_organisation': 2,\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:30:31.793572Z","iopub.execute_input":"2025-04-19T03:30:31.793769Z","iopub.status.idle":"2025-04-19T03:30:31.798695Z","shell.execute_reply.started":"2025-04-19T03:30:31.793738Z","shell.execute_reply":"2025-04-19T03:30:31.798028Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"wandb.login(key='f15dba29e56f32e9c31d598bce5bc7a3c76de62e')\nwandb.init(project=\"DA6401_Assignment2\", config=config, name=\"fixed_config_train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:30:36.973167Z","iopub.execute_input":"2025-04-19T03:30:36.973444Z","iopub.status.idle":"2025-04-19T03:30:36.989316Z","shell.execute_reply.started":"2025-04-19T03:30:36.973426Z","shell.execute_reply":"2025-04-19T03:30:36.988713Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_Assignment2/runs/3pjlxxxt?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7c5094f4bd90>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"def get_transform(use_augmentation):\n    if use_augmentation:\n        return transforms.Compose([\n            transforms.RandomCrop(50, padding=1),\n            transforms.RandomGrayscale(p=0.1),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(degrees=(0, 20)),\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(\n                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n            )\n        ])\n    return transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n        )\n    ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:30:37.889147Z","iopub.execute_input":"2025-04-19T03:30:37.889381Z","iopub.status.idle":"2025-04-19T03:30:37.895790Z","shell.execute_reply.started":"2025-04-19T03:30:37.889365Z","shell.execute_reply":"2025-04-19T03:30:37.895049Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def train_model():\n    # Load and split dataset\n    dataset = ImageFolder(root=training_data_path, transform=get_transform(config['use_augmentation']))\n    train_size = int(0.8 * len(dataset))\n    val_size = len(dataset) - train_size\n    train_set, val_set = random_split(dataset, [train_size, val_size])\n    train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True)\n    val_loader = DataLoader(val_set, batch_size=config['batch_size'], shuffle=False)\n\n    # Setup activations\n    activations = {\n        'silu': nn.SiLU(),\n        'sigmoid': nn.Sigmoid(),\n    }\n\n    # Initialize model\n    gc.collect()\n    torch.cuda.empty_cache()\n    model = CNN(\n        input_dimension=(3, 224, 224),\n        number_of_filters=config['number_of_filters'],\n        filter_size=(config['filter_size'], config['filter_size']),\n        stride=config['stride'],\n        padding=config['padding'],\n        max_pooling_size=(config['max_pooling_size'], config['max_pooling_size']),\n        n_neurons=config['n_neurons'],\n        n_classes=config['n_classes'],\n        conv_activation=activations[config['conv_activation']],\n        dense_activation=activations[config['dense_activation']],\n        dropout_rate=config['dropout_rate'],\n        use_batchnorm=config['use_batchnorm'],\n        factor=config['factor'],\n        dropout_organisation=config['dropout_organisation'],\n    ).to(device)\n\n    # Training setup\n    optimizer = Adam(model.parameters(), lr=config['learning_rate'])\n    criterion = nn.CrossEntropyLoss()\n    \n    # Metrics tracking\n    train_losses = []\n    train_accuracies = []\n    val_losses = []\n    val_accuracies = []\n    best_val_accuracy = 0.0\n\n    # Training loop\n    for epoch in range(config['epochs']):\n        # Training phase\n        model.train()\n        train_loss = 0\n        correct = 0\n        total = 0\n        \n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            optimizer.zero_grad()\n            pred = model(x)\n            loss = criterion(pred, y)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item() * x.size(0)\n            correct += (pred.argmax(1) == y).sum().item()\n            total += y.size(0)\n            del x, y\n            \n        train_accuracy = 100 * correct / total\n        avg_train_loss = train_loss / total\n        train_losses.append(avg_train_loss)\n        train_accuracies.append(train_accuracy)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                pred = model(x)\n                loss = criterion(pred, y)\n                val_loss += loss.item() * x.size(0)\n                correct += (pred.argmax(1) == y).sum().item()\n                total += y.size(0)\n                del x, y\n                \n        val_accuracy = 100 * correct / total\n        avg_val_loss = val_loss / total\n        val_losses.append(avg_val_loss)\n        val_accuracies.append(val_accuracy)\n\n        wandb.log({\n            'epoch': epoch+1,\n            'train_loss': avg_train_loss,\n            'train_accuracy': train_accuracy,\n            'val_loss': avg_val_loss,\n            'val_accuracy': val_accuracy\n        })\n\n        print(f\"Epoch [{epoch+1}/{config['epochs']}]\")\n        print(f\"Train Loss: {avg_train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n        print(f\"Val Loss: {avg_val_loss:.4f} | Val Accuracy: {val_accuracy:.2f}%\")\n        print(\"-\" * 50)\n\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            torch.save(model.state_dict(), \"best_model_fixed_config_train.pth\")\n\n    # Plot training history\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Val Loss')\n    plt.title('Loss History')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(train_accuracies, label='Train Accuracy')\n    plt.plot(val_accuracies, label='Val Accuracy')\n    plt.title('Accuracy History')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig('training_history.png')\n    plt.close()\n\n    print(f\"Best validation accuracy: {best_val_accuracy:.2f}%\")\n    print(\"Training history plot saved as 'training_history.png'\")\n    \n    wandb.finish()\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:34:43.400096Z","iopub.execute_input":"2025-04-19T03:34:43.400847Z","iopub.status.idle":"2025-04-19T03:34:43.414572Z","shell.execute_reply.started":"2025-04-19T03:34:43.400813Z","shell.execute_reply":"2025-04-19T03:34:43.413954Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    model = train_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T03:34:47.653619Z","iopub.execute_input":"2025-04-19T03:34:47.654257Z","iopub.status.idle":"2025-04-19T04:58:59.774921Z","shell.execute_reply.started":"2025-04-19T03:34:47.654227Z","shell.execute_reply":"2025-04-19T04:58:59.774126Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/15]\nTrain Loss: 2.2338 | Train Accuracy: 18.13%\nVal Loss: 2.1703 | Val Accuracy: 21.25%\n--------------------------------------------------\nEpoch [2/15]\nTrain Loss: 2.1710 | Train Accuracy: 21.22%\nVal Loss: 2.1636 | Val Accuracy: 21.35%\n--------------------------------------------------\nEpoch [3/15]\nTrain Loss: 2.1522 | Train Accuracy: 22.38%\nVal Loss: 2.1399 | Val Accuracy: 21.80%\n--------------------------------------------------\nEpoch [4/15]\nTrain Loss: 2.1276 | Train Accuracy: 23.63%\nVal Loss: 2.1052 | Val Accuracy: 23.25%\n--------------------------------------------------\nEpoch [5/15]\nTrain Loss: 2.1265 | Train Accuracy: 22.92%\nVal Loss: 2.1156 | Val Accuracy: 24.60%\n--------------------------------------------------\nEpoch [6/15]\nTrain Loss: 2.1022 | Train Accuracy: 25.24%\nVal Loss: 2.0795 | Val Accuracy: 25.95%\n--------------------------------------------------\nEpoch [7/15]\nTrain Loss: 2.1012 | Train Accuracy: 24.63%\nVal Loss: 2.0914 | Val Accuracy: 24.05%\n--------------------------------------------------\nEpoch [8/15]\nTrain Loss: 2.1034 | Train Accuracy: 24.49%\nVal Loss: 2.1188 | Val Accuracy: 24.35%\n--------------------------------------------------\nEpoch [9/15]\nTrain Loss: 2.1057 | Train Accuracy: 24.78%\nVal Loss: 2.0688 | Val Accuracy: 26.05%\n--------------------------------------------------\nEpoch [10/15]\nTrain Loss: 2.0704 | Train Accuracy: 26.39%\nVal Loss: 2.0711 | Val Accuracy: 25.75%\n--------------------------------------------------\nEpoch [11/15]\nTrain Loss: 2.0575 | Train Accuracy: 26.08%\nVal Loss: 2.0440 | Val Accuracy: 26.30%\n--------------------------------------------------\nEpoch [12/15]\nTrain Loss: 2.0605 | Train Accuracy: 26.40%\nVal Loss: 2.0606 | Val Accuracy: 25.50%\n--------------------------------------------------\nEpoch [13/15]\nTrain Loss: 2.0629 | Train Accuracy: 26.19%\nVal Loss: 2.0590 | Val Accuracy: 25.10%\n--------------------------------------------------\nEpoch [14/15]\nTrain Loss: 2.0486 | Train Accuracy: 27.14%\nVal Loss: 2.0270 | Val Accuracy: 27.50%\n--------------------------------------------------\nEpoch [15/15]\nTrain Loss: 2.0405 | Train Accuracy: 27.22%\nVal Loss: 2.0447 | Val Accuracy: 27.00%\n--------------------------------------------------\nBest validation accuracy: 27.50%\nTraining history plot saved as 'training_history.png'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▂▃▅▆▄▄▆▆▇▆▅█▇</td></tr><tr><td>val_loss</td><td>██▇▅▅▄▄▅▃▃▂▃▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_accuracy</td><td>27.2159</td></tr><tr><td>train_loss</td><td>2.04051</td></tr><tr><td>val_accuracy</td><td>27</td></tr><tr><td>val_loss</td><td>2.04466</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fixed_config_train</strong> at: <a href='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_Assignment2/runs/3pjlxxxt' target=\"_blank\">https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_Assignment2/runs/3pjlxxxt</a><br> View project at: <a href='https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_Assignment2' target=\"_blank\">https://wandb.ai/ma23c047-indian-institute-of-technology-madras/DA6401_Assignment2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250419_032909-3pjlxxxt/logs</code>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}